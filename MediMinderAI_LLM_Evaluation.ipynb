{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awT4XSVWYsip"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install sentence-transformers scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Sridevi will give you this file ---\n",
        "# Make sure to upload it to your Colab environment\n",
        "FILE_PATH = 'llm_outputs.csv' # Or whatever she names it\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(FILE_PATH)\n",
        "    print(\"âœ… Data loaded successfully. Here's a sample:\")\n",
        "    print(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"ðŸ›‘ Error: Please upload the file '{FILE_PATH}' from Sridevi.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Get the texts from the DataFrame\n",
        "original_texts = df['cleaned_transcription'].tolist()\n",
        "generated_summaries = df['generated_summary'].tolist()\n",
        "\n",
        "# Generate embeddings for both sets of text\n",
        "print(\"\\nGenerating vector embeddings...\")\n",
        "original_embeddings = model.encode(original_texts, show_progress_bar=True)\n",
        "summary_embeddings = model.encode(generated_summaries, show_progress_bar=True)\n",
        "print(\"âœ… Embeddings created.\")\n",
        "\n",
        "# Calculate cosine similarity for each pair\n",
        "# This compares each summary to its corresponding original text\n",
        "scores = []\n",
        "for i in range(len(original_embeddings)):\n",
        "    # The reshape(1, -1) is necessary for the function\n",
        "    score = cosine_similarity(original_embeddings[i].reshape(1, -1), summary_embeddings[i].reshape(1, -1))\n",
        "    scores.append(score[0][0])\n",
        "\n",
        "# Add the scores back to the DataFrame\n",
        "df['consistency_score'] = scores\n",
        "\n",
        "print(\"\\nâœ… Factual consistency scores calculated.\")"
      ],
      "metadata": {
        "id": "UPnrBbxXYx3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- LLM Evaluation Report ---\")\n",
        "\n",
        "# Calculate and print overall metrics\n",
        "average_score = df['consistency_score'].mean()\n",
        "min_score = df['consistency_score'].min()\n",
        "max_score = df['consistency_score'].max()\n",
        "\n",
        "print(f\"\\nAverage Consistency Score: {average_score:.4f}\")\n",
        "print(f\"Minimum Consistency Score: {min_score:.4f}\")\n",
        "print(f\"Maximum Consistency Score: {max_score:.4f}\")\n",
        "\n",
        "# Show the top 3 WORST performing summaries for manual review\n",
        "print(\"\\n--- Top 3 Lowest Scores (Needs Review) ---\")\n",
        "print(df.sort_values(by='consistency_score', ascending=True).head(3))\n",
        "\n",
        "# Show the top 3 BEST performing summaries\n",
        "print(\"\\n--- Top 3 Highest Scores (Good Examples) ---\")\n",
        "print(df.sort_values(by='consistency_score', ascending=False).head(3))"
      ],
      "metadata": {
        "id": "mpAZGYdGY0SP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}